# -*- coding: utf-8 -*-
"""
æµ‹é‡ Qwen2.5-VL-7B-Instruct è§†é¢‘ç‰¹å¾æå–è€—æ—¶ï¼ˆä»…è§†è§‰ç¼–ç ï¼Œä¸åšç”Ÿæˆï¼‰
- å•æ¬¡ï¼šæ¨¡å‹åŠ è½½æ—¶é—´ / é¢„å¤„ç†æ—¶é—´ / è§†è§‰ç¼–ç æ—¶é—´
- æ‰¹é‡ï¼šé‡å¤ N æ¬¡ï¼Œæ‰“å°è¡¨æ ¼å¹¶å¯¼å‡º CSV
- OOM è‡ªåŠ¨é™é…é‡è¯•ï¼ˆé™ä½ max_pixelsï¼‰
- åœ¨ CSV æœ«å°¾è¿½åŠ â€œåˆ—è§£é‡Šâ€åŒºå—ï¼ˆEXPLAIN_START/EXPLAIN/EXPLAIN_ENDï¼‰
"""

import os
import time
import csv
import argparse
import statistics as stats
from datetime import datetime
import traceback

import torch
from modelscope import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info


def sync_cuda():
    if torch.cuda.is_available():
        torch.cuda.synchronize()


def build_messages(video_path, fps, min_frames, max_frames, max_pixels):
    video_uri = video_path if video_path.startswith("file://") else f"file://{video_path}"
    return [
        {
            "role": "user",
            "content": [
                {
                    "type": "video",
                    "video": video_uri,
                    "fps": fps,
                    "min_frames": min_frames,
                    "max_frames": max_frames,
                    "max_pixels": max_pixels,
                },
                {"type": "text", "text": "Describe this video."},
            ],
        }
    ]


def one_trial(model, processor, args, cur_max_pixels):
    """æ‰§è¡Œä¸€æ¬¡å®Œæ•´æµç¨‹å¹¶è¿”å›åº¦é‡ç»“æœå­—å…¸ï¼›å¯èƒ½æŠ›å‡ºå¼‚å¸¸ï¼ˆå¤–å±‚å¤„ç† OOM é‡è¯•ï¼‰"""
    # reset å³°å€¼æ˜¾å­˜ç»Ÿè®¡
    if torch.cuda.is_available():
        torch.cuda.reset_peak_memory_stats()

    # é¢„å¤„ç†
    t2 = time.perf_counter()
    messages = build_messages(args.video_path, args.fps, args.min_frames, args.max_frames, cur_max_pixels)
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    image_inputs, video_inputs = process_vision_info(messages)
    inputs = processor(
        text=[text],
        images=image_inputs,
        videos=video_inputs,
        padding=True,
        return_tensors="pt",
    )
    if args.device == "cuda" and torch.cuda.is_available():
        inputs = inputs.to("cuda")
    sync_cuda()
    t3 = time.perf_counter()
    preprocess_s = t3 - t2

    # å…³é”®å¼ é‡
    pixel_values_videos = inputs.get("pixel_values_videos", None)
    video_grid_thw = inputs.get("video_grid_thw", None)
    if pixel_values_videos is None or video_grid_thw is None:
        raise RuntimeError("æœªæ‰¾åˆ° pixel_values_videos / video_grid_thwï¼›è¯·ç¡®è®¤ qwen_vl_utils ä¸ processor ç‰ˆæœ¬åŒ¹é…ã€‚")

    # è§†è§‰ç¼–ç ï¼ˆä»…å‰å‘ï¼‰
    start_event = torch.cuda.Event(enable_timing=True) if torch.cuda.is_available() else None
    end_event = torch.cuda.Event(enable_timing=True) if torch.cuda.is_available() else None

    sync_cuda()
    t4 = time.perf_counter()
    if start_event is not None:
        start_event.record()

    with torch.no_grad():
        autocast_dtype = None
        if args.dtype in ("float16", "bfloat16") and torch.cuda.is_available():
            autocast_dtype = torch.float16 if args.dtype == "float16" else torch.bfloat16
        cm = torch.autocast(device_type="cuda", dtype=autocast_dtype) if autocast_dtype else torch.cuda.amp.autocast(enabled=False)
        with cm:
            _ = model.get_video_features(
                pixel_values_videos=pixel_values_videos,
                video_grid_thw=video_grid_thw
            )

    if end_event is not None:
        end_event.record()
        torch.cuda.synchronize()

    t5 = time.perf_counter()
    wall_forward_s = t5 - t4
    gpu_forward_s = None
    if start_event is not None and end_event is not None:
        gpu_forward_s = start_event.elapsed_time(end_event) / 1000.0  # ms->s

    # å³°å€¼æ˜¾å­˜ï¼ˆMiBï¼‰
    peak_mib = None
    if torch.cuda.is_available():
        peak_bytes = torch.cuda.max_memory_allocated()
        peak_mib = round(peak_bytes / (1024 * 1024), 1)

    # å½¢çŠ¶ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    vshape = tuple(pixel_values_videos.shape) if hasattr(pixel_values_videos, "shape") else None
    thw = video_grid_thw.detach().cpu().tolist() if hasattr(video_grid_thw, "detach") else None

    # æ¸…ç†ä¸­é—´å¼•ç”¨ï¼Œåˆ©äºåç»­è¯•æ¬¡
    del inputs, pixel_values_videos, video_grid_thw
    torch.cuda.empty_cache()

    return {
        "preprocess_s": preprocess_s,
        "gpu_forward_s": gpu_forward_s,
        "wall_forward_s": wall_forward_s,
        "peak_mib": peak_mib,
        "max_pixels_used": cur_max_pixels,
        "pixel_values_videos_shape": vshape,
        "video_grid_thw": thw,
        "status": "ok",
    }


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_path", type=str, default="/home/l40/newdisk1/mfl/qwenvl/Qwen2.5-VL-7B-Instruct")
    parser.add_argument("--video_path", type=str, default="/home/l40/newdisk1/mfl/videosur/data/videos/test.mp4")
    parser.add_argument("--fps", type=float, default=2.0)
    parser.add_argument("--min_frames", type=int, default=4)
    parser.add_argument("--max_frames", type=int, default=256)
    parser.add_argument("--max_pixels", type=int, default=360 * 420)
    parser.add_argument("--dtype", type=str, default="bfloat16", choices=["float16", "bfloat16", "float32"])
    parser.add_argument("--device", type=str, default="cuda")
    parser.add_argument("--print_feature_shape", action="store_true")

    # å¤šæ¬¡æµ‹è¯• & å¯¼å‡º
    parser.add_argument("--repeat", type=int, default=10, help="é‡å¤è¯•æ¬¡")
    parser.add_argument("--warmup", type=int, default=1, help="é¢„çƒ­æ¬¡æ•°ï¼ˆä¸è®¡å…¥ç»Ÿè®¡ï¼‰")
    parser.add_argument("--sleep_between", type=float, default=0.1, help="ä¸¤æ¬¡è¯•éªŒé—´éš”ç§’æ•°")
    parser.add_argument("--csv_out", type=str, default="/home/l40/newdisk1/mfl/videosur/test/qwen25vl_bench.csv")

    # OOM é™é…
    parser.add_argument("--backoff_on_oom", action="store_true", help="å‘ç”Ÿ OOM æ—¶è‡ªåŠ¨é™ä½ max_pixels é‡è¯•")
    parser.add_argument("--min_max_pixels", type=int, default=160 * 224, help="è‡ªåŠ¨é™é…çš„ max_pixels ä¸‹é™")
    parser.add_argument("--backoff_ratio", type=float, default=0.8, help="æ¯æ¬¡ OOM é™é…å€ç‡ï¼ˆ0.8=é™ 20%ï¼‰")

    args = parser.parse_args()

    # dtype
    dtype_map = {"float16": torch.float16, "bfloat16": torch.bfloat16, "float32": torch.float32}
    torch_dtype = dtype_map[args.dtype]

    # å»ºè®®å¼€å¯ï¼šé™ä½ç¢ç‰‡
    if "PYTORCH_CUDA_ALLOC_CONF" not in os.environ:
        os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

    torch.backends.cudnn.benchmark = True

    # ============ æ¨¡å‹åŠ è½½ ============
    print("â³ æ­£åœ¨åŠ è½½æ¨¡å‹ä¸å¤„ç†å™¨ ...")
    t0 = time.perf_counter()
    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        args.model_path,
        torch_dtype=torch_dtype,
        device_map="auto",
    )
    processor = AutoProcessor.from_pretrained(args.model_path)
    sync_cuda()
    t1 = time.perf_counter()
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œç”¨æ—¶: {t1 - t0:.2f} sï¼›dtype={torch_dtype}, device_map=auto")

    # ============ é¢„çƒ­ï¼ˆä¸è®¡å…¥ç»Ÿè®¡ï¼‰ ============
    warmup_runs = max(0, args.warmup)
    cur_max_pixels = int(args.max_pixels)
    for i in range(warmup_runs):
        try:
            _ = one_trial(model, processor, args, cur_max_pixels)
        except Exception as e:
            print(f"âš ï¸ é¢„çƒ­ç¬¬ {i+1} æ¬¡å¤±è´¥ï¼š{e}")

    # ============ æ­£å¼å¤šæ¬¡æµ‹è¯• ============
    results = []
    for i in range(args.repeat):
        retries = 0
        while True:
            try:
                res = one_trial(model, processor, args, cur_max_pixels)
                res["run"] = i + 1
                results.append(res)
                # æ‰“å°å•æ¬¡ç»“æœç®€è¡¨ï¼ˆé¿å…åµŒå¥— f-string çš„å¼•å·æ··æ·†ï¼Œå…ˆæ ¼å¼åŒ–å„åˆ—ï¼‰
                prep = f"{res['preprocess_s']:.3f}" if res.get("preprocess_s") is not None else " - "
                gpu = f"{res['gpu_forward_s']:.4f}" if res.get("gpu_forward_s") is not None else " - "
                wall = f"{res['wall_forward_s']:.4f}" if res.get("wall_forward_s") is not None else " - "
                peak = f"{res['peak_mib']}" if res.get("peak_mib") is not None else " - "
                print(f"[Run {i+1:02d}] prep={prep}s  gpu={gpu}s  wall={wall}s  peak={peak}MiB  max_pixels={cur_max_pixels}")
                break
            except RuntimeError as e:
                msg = str(e)
                if "CUDA out of memory" in msg and args.backoff_on_oom:
                    retries += 1
                    if retries > 3:
                        print("âŒ OOM è¿ç»­é‡è¯•å¤±è´¥ï¼ˆå·²å°è¯• 3 æ¬¡ï¼‰ï¼Œè·³è¿‡æœ¬æ¬¡ã€‚")
                        results.append({
                            "run": i + 1, "status": "oom_failed",
                            "preprocess_s": None, "gpu_forward_s": None, "wall_forward_s": None,
                            "peak_mib": None, "max_pixels_used": cur_max_pixels,
                            "pixel_values_videos_shape": None, "video_grid_thw": None
                        })
                        break
                    # é™é…é‡è¯•
                    new_max = int(cur_max_pixels * args.backoff_ratio)
                    if new_max < args.min_max_pixels:
                        print(f"âŒ OOMï¼Œä½†å·²åˆ°è¾¾ max_pixels ä¸‹é™ï¼ˆ{args.min_max_pixels}ï¼‰ï¼Œæ”¾å¼ƒæœ¬æ¬¡ã€‚")
                        results.append({
                            "run": i + 1, "status": "oom_min_reached",
                            "preprocess_s": None, "gpu_forward_s": None, "wall_forward_s": None,
                            "peak_mib": None, "max_pixels_used": cur_max_pixels,
                            "pixel_values_videos_shape": None, "video_grid_thw": None
                        })
                        break
                    print(f"âš ï¸ OOMï¼Œé™ä½ max_pixels: {cur_max_pixels} -> {new_max} åé‡è¯•ï¼ˆç¬¬ {retries} æ¬¡ï¼‰")
                    cur_max_pixels = new_max
                    torch.cuda.empty_cache()
                    time.sleep(0.1)
                    continue
                else:
                    print(f"âŒ ç¬¬ {i+1} æ¬¡å¤±è´¥ï¼š{e}\n{traceback.format_exc()}")
                    results.append({
                        "run": i + 1, "status": "failed",
                        "preprocess_s": None, "gpu_forward_s": None, "wall_forward_s": None,
                        "peak_mib": None, "max_pixels_used": cur_max_pixels,
                        "pixel_values_videos_shape": None, "video_grid_thw": None
                    })
                    break
        time.sleep(max(0.0, args.sleep_between))

    # ============ ç»Ÿè®¡æ±‡æ€» ============
    ok_runs = [r for r in results if r.get("status", "ok") == "ok"]

    def _col(name):
        vals = [r[name] for r in ok_runs if r.get(name) is not None]
        return (stats.mean(vals), stats.pstdev(vals)) if vals else (None, None)

    mean_prep, std_prep = _col("preprocess_s")
    mean_gpu, std_gpu = _col("gpu_forward_s")
    mean_wall, std_wall = _col("wall_forward_s")

    # ç»ˆç«¯è¡¨æ ¼
    header_line = f"{'Run':>3} | {'Prep(s)':>7} | {'GPU(s)':>7} | {'Wall(s)':>7} | {'Peak(MiB)':>9} | {'max_pixels':>10} | Status"
    print("\n" + header_line)
    print("-" * len(header_line))
    for r in results:
        prep = f"{r['preprocess_s']:.3f}" if r.get("preprocess_s") is not None else " - "
        gpu = f"{r['gpu_forward_s']:.4f}" if r.get("gpu_forward_s") is not None else " - "
        wall = f"{r['wall_forward_s']:.4f}" if r.get("wall_forward_s") is not None else " - "
        peak = f"{r['peak_mib']}" if r.get("peak_mib") is not None else " - "
        maxp = str(r.get("max_pixels_used", "-"))
        line = f"{r['run']:>3} | {prep:>7} | {gpu:>7} | {wall:>7} | {peak:>9} | {maxp:>10} | {r.get('status','-')}"
        print(line)
    print("-" * len(header_line))
    mean_prep_s = f"{mean_prep:.3f}" if mean_prep is not None else " - "
    mean_gpu_s = f"{mean_gpu:.4f}" if mean_gpu is not None else " - "
    mean_wall_s = f"{mean_wall:.4f}" if mean_wall is not None else " - "
    std_prep_s = f"{std_prep:.3f}" if std_prep is not None else " - "
    std_gpu_s = f"{std_gpu:.4f}" if std_gpu is not None else " - "
    std_wall_s = f"{std_wall:.4f}" if std_wall is not None else " - "
    print(f"MEAN | {mean_prep_s:>7} | {mean_gpu_s:>7} | {mean_wall_s:>7} | {'':>9} | {'':>10} | "
          f"(std: prep={std_prep_s}, gpu={std_gpu_s}, wall={std_wall_s})")

    # å†™ CSV
    header = [
        "timestamp", "run", "status", "dtype", "fps", "min_frames", "max_frames",
        "max_pixels_used", "preprocess_s", "gpu_forward_s", "wall_forward_s",
        "peak_mib", "pixel_values_videos_shape", "video_grid_thw"
    ]

    os.makedirs(os.path.dirname(args.csv_out), exist_ok=True)
    with open(args.csv_out, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(header)
        ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        for r in results:
            writer.writerow([
                ts, r["run"], r.get("status", ""),
                args.dtype, args.fps, args.min_frames, args.max_frames,
                r.get("max_pixels_used", ""),
                r.get("preprocess_s", ""), r.get("gpu_forward_s", ""), r.get("wall_forward_s", ""),
                r.get("peak_mib", ""), r.get("pixel_values_videos_shape", ""), r.get("video_grid_thw", "")
            ])
        # è¿½åŠ ç»Ÿè®¡
        writer.writerow([ts, "MEAN", "ok-only", args.dtype, args.fps, args.min_frames, args.max_frames,
                         "", mean_prep, mean_gpu, mean_wall, "", "", ""])
        writer.writerow([ts, "STD", "ok-only", args.dtype, args.fps, args.min_frames, args.max_frames,
                         "", std_prep, std_gpu, std_wall, "", "", ""])

        # === è¿½åŠ åˆ—è§£é‡Šï¼ˆæ¯è¡Œä¸è¡¨å¤´åŒåˆ—æ•°ï¼Œæœªç”¨åˆ—ç”¨ç©ºä¸²è¡¥é½ï¼‰ ===
        explain = {
            "timestamp": "å†™å…¥æ—¶é—´(æœ¬åœ°)",
            "run": "ç¬¬å‡ æ¬¡/MEAN/STD",
            "status": "çŠ¶æ€: ok/failed/oom_failed/oom_min_reached",
            "dtype": "æ•°å€¼ç²¾åº¦: bfloat16/float16/float32",
            "fps": "æŠ½å¸§ç›®æ ‡FPS",
            "min_frames": "æœ€å°‘å¸§æ•°(æŠ½å¸§ä¸‹é™)",
            "max_frames": "æœ€å¤šå¸§æ•°(æŠ½å¸§ä¸Šé™)",
            "max_pixels_used": "æœ¬æ¬¡ä½¿ç”¨çš„æ¯å¸§åƒç´ ä¸Šé™(è¶Šå¤§â†’åˆ†è¾¨ç‡æ›´é«˜â†’æ›´æ…¢/æ›´å æ˜¾å­˜)",
            "preprocess_s": "é¢„å¤„ç†æ—¶é—´(ç§’): è§£ç /ç¼©æ”¾/æ‰“åŒ…+æ‹·è´åˆ°GPU(å«åŒæ­¥)",
            "gpu_forward_s": "è§†è§‰ç¼–ç å‰å‘çš„CUDAäº‹ä»¶è®¡æ—¶(ç§’)",
            "wall_forward_s": "è§†è§‰ç¼–ç å‰å‘çš„å¢™é’Ÿæ—¶é—´(ç§’, å«åŒæ­¥)",
            "peak_mib": "å³°å€¼æ˜¾å­˜(MiB): torch.cuda.max_memory_allocated()",
            "pixel_values_videos_shape": "è¾“å…¥å¼ é‡å½¢çŠ¶(ä»…è®°å½•; ç¬¬ä¸€ç»´â‰ˆè§†è§‰tokenæ•°)",
            "video_grid_thw": "ç‰¹å¾ç½‘æ ¼[T,H,W] (tokenç©ºé—´ï¼Œè€Œéåƒç´ )"
        }

        # åˆ†éš”è¡Œï¼ˆæ ‡è®°è§£é‡ŠåŒºèµ·å§‹ï¼‰
        writer.writerow(["EXPLAIN_START"] + [""] * (len(header) - 1))
        # é€åˆ—å†™è§£é‡Šï¼š["EXPLAIN", åˆ—å, è§£é‡Š, ...ç©º]
        for col in header:
            row = ["EXPLAIN", col, explain.get(col, "")]
            row += [""] * (len(header) - len(row))
            writer.writerow(row)
        # ç»“æŸæ ‡è®°
        writer.writerow(["EXPLAIN_END"] + [""] * (len(header) - 1))

    print(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ° CSV: {args.csv_out}")

    # å¯é€‰ï¼šæ‰“å°ä¸€æ¬¡å½¢çŠ¶ & ç½‘æ ¼
    if args.print_feature_shape and ok_runs:
        sample = ok_runs[-1]
        print("\nğŸ“ Sample Shapes")
        print("pixel_values_videos_shape:", sample.get("pixel_values_videos_shape"))
        print("video_grid_thw:", sample.get("video_grid_thw"))

    print("å®Œæˆï¼")


if __name__ == "__main__":
    main()
