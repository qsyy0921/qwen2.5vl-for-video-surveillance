# -*- coding: utf-8 -*-
import os
import time
import math
import shutil
import traceback
import cv2
import torch
import pandas as pd

# ====== è·¯å¾„é…ç½® ======
MODEL_PATH = "/home/l40/newdisk1/mfl/qwenvl/Qwen2.5-VL-7B-Instruct"
VIDEO_PATH = "/home/l40/newdisk1/mfl/videosur/data/videos/car.mp4"
OUT_DIR = "/home/l40/newdisk1/mfl/videosur/test"
SAMPLED_DIR = os.path.join(OUT_DIR, "sampled_videos")
EXCEL_PATH = os.path.join(OUT_DIR, "center_benchmark.xlsx")

os.makedirs(SAMPLED_DIR, exist_ok=True)

# ====== æ¨ç†å‚æ•°ï¼ˆå°½é‡é¿å…OOMï¼‰ ======
# â†“ ä¿å­˜æˆç‰‡æ®µçš„è§†é¢‘å¸§ç‡ï¼ˆä¸ºäº†æ–‡ä»¶å…¼å®¹ä¸ä½“ç§¯ï¼‰
SAVE_FPS_CAP = 15  # ä¿å­˜ç‰‡æ®µä¸è¶…è¿‡ 15 FPS
SAVE_SIZE_MAX = 320  # ç‰‡æ®µæœ€å¤§è¾¹ç¼©åˆ° 320ï¼Œå‡å°ä½“ç§¯

# â†“ æ¨¡å‹æ¨ç†ç«¯çš„ä¸‹é‡‡æ ·ï¼ˆå…³é”®ï¼šé¿å… tokens/features ä¸åŒ¹é…ä¸æ˜¾å­˜çˆ†ï¼‰
INFER_FPS = 1.0            # ä¼ ç»™ messages çš„ fpsï¼ˆè®©Qwenå†…éƒ¨é‡‡æ ·ï¼‰
INFER_MAX_PIXELS = 360 * 420  # å‚è€ƒå®˜æ–¹ç¤ºä¾‹ï¼Œæ§åˆ¶è§†è§‰tokensè§„æ¨¡
MAX_NEW_TOKENS = 64

# ====== ç‰‡æ®µæ¯”ä¾‹ï¼šä» 80% åˆ° 50%ï¼Œæ¯æ¬¡ -5% ======
RATIOS = [80, 75, 70, 65, 60, 55, 50]

# ====== å·¥å…·å‡½æ•°ï¼šæ£€æŸ¥ ffmpeg å­˜åœ¨ä¸å¦ ======
def have_ffmpeg() -> bool:
    return shutil.which("ffmpeg") is not None

# ====== æ ¹æ®ç³»ç»Ÿæƒ…å†µé€‰æ‹©å®¹å™¨ä¸ç¼–ç å™¨ ======
def pick_video_output(path_no_ext: str):
    """
    è¿”å› (out_path, fourcc)
    ä¼˜å…ˆ mp4v/mp4ï¼ˆéœ€è¦ ffmpegï¼‰ï¼Œå¦åˆ™å›é€€åˆ° avi+MJPGã€‚
    """
    if have_ffmpeg():
        return path_no_ext + ".mp4", cv2.VideoWriter_fourcc(*"mp4v")
    else:
        return path_no_ext + ".avi", cv2.VideoWriter_fourcc(*"MJPG")

# ====== è¯»å–è§†é¢‘å…ƒæ•°æ® ======
def read_meta(video_path):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘ï¼š{video_path}")
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = float(cap.get(cv2.CAP_PROP_FPS)) or 0.0
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()
    if fps <= 0:
        # å®¹é”™ï¼šä¸ªåˆ«ç¼–ç å¯èƒ½ç»™ 0ï¼Œè¿™é‡Œå…œåº•
        fps = 30.0
    return total_frames, fps, width, height

# ====== å±…ä¸­è£å‰ªç‰‡æ®µåˆ°æ–°æ–‡ä»¶ï¼ˆå¸¦ç¼–ç å™¨å›é€€ï¼‰ ======
def write_center_clip(src_path, ratio_pct, save_dir):
    """
    ratio_pct: 80/75/.../50
    è¿”å›å­—å…¸ï¼š{path, start_sec, dur_sec, fps, frames, note}
    """
    total_frames, src_fps, w, h = read_meta(src_path)
    duration_sec = total_frames / src_fps

    # ç¡®å®šç‰‡æ®µæ—¶é—´èŒƒå›´ï¼ˆå–è§†é¢‘ä¸­é—´ ratio% çš„æ—¶é•¿ï¼‰
    frac = ratio_pct / 100.0
    dur_sec = duration_sec * frac
    start_sec = (duration_sec - dur_sec) / 2.0
    end_sec = start_sec + dur_sec

    # ä¿å­˜ç”¨çš„ fpsï¼ˆä¸è¶…è¿‡ä¸Šé™ï¼‰
    out_fps = min(src_fps, float(SAVE_FPS_CAP))

    # ç›®æ ‡å°ºå¯¸ï¼ˆç­‰æ¯”ä¾‹æŠŠæœ€é•¿è¾¹ç¼©åˆ° SAVE_SIZE_MAXï¼‰
    long_edge = max(w, h)
    scale = SAVE_SIZE_MAX / long_edge if long_edge > SAVE_SIZE_MAX else 1.0
    out_w = int(round(w * scale))
    out_h = int(round(h * scale))

    # å‡†å¤‡è¾“å‡º
    base_noext = os.path.join(save_dir, f"clip_ratio{ratio_pct}")
    out_path, fourcc = pick_video_output(base_noext)

    # æ‰“å¼€è¾“å…¥ã€è¾“å‡º
    cap = cv2.VideoCapture(src_path)
    if not cap.isOpened():
        return None, f"æ— æ³•æ‰“å¼€æºè§†é¢‘ï¼š{src_path}"

    writer = cv2.VideoWriter(out_path, fourcc, out_fps, (out_w, out_h))
    if not writer.isOpened():
        # å°è¯•å›é€€ï¼ˆå¦‚æœå‰é¢å°±æ˜¯mp4ï¼Œåˆ™å›é€€æˆaviï¼›åä¹‹äº¦ç„¶ï¼‰
        cap.release()
        if out_path.endswith(".mp4"):
            out_path = base_noext + ".avi"
            fourcc = cv2.VideoWriter_fourcc(*"MJPG")
        else:
            out_path = base_noext + ".mp4"
            fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        cap = cv2.VideoCapture(src_path)
        writer = cv2.VideoWriter(out_path, fourcc, out_fps, (out_w, out_h))
        if not writer.isOpened():
            cap.release()
            return None, "æ‰“å¼€VideoWriterå¤±è´¥ï¼ˆmp4/aviéƒ½å¤±è´¥ï¼‰"

    # å®šä½åˆ°èµ·å§‹å¸§
    start_frame = int(round(start_sec * src_fps))
    end_frame = int(round(end_sec * src_fps))
    start_frame = max(0, min(total_frames - 1, start_frame))
    end_frame = max(start_frame + 1, min(total_frames, end_frame))

    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
    write_cnt = 0

    for fr in range(start_frame, end_frame):
        ok, frame = cap.read()
        if not ok:
            break
        if scale != 1.0:
            frame = cv2.resize(frame, (out_w, out_h), interpolation=cv2.INTER_AREA)
        writer.write(frame)
        write_cnt += 1

    writer.release()
    cap.release()

    # ç®€å•æ ¡éªŒ
    if write_cnt == 0 or not os.path.exists(out_path) or os.path.getsize(out_path) == 0:
        return None, "å¯¼å‡ºç‰‡æ®µå¤±è´¥ï¼ˆå¯èƒ½æ— å¸§/ç¼–ç å™¨ä¸å…¼å®¹ï¼‰"

    return {
        "path": out_path,
        "start_sec": start_sec,
        "dur_sec": dur_sec,
        "fps": out_fps,
        "frames": write_cnt,
    }, "ok"

# ====== åŠ è½½æ¨¡å‹ï¼ˆModelScope ç‰ˆï¼Œå®˜æ–¹æ¨èï¼‰ ======
def load_model_and_processor():
    from modelscope import Qwen2_5_VLForConditionalGeneration, AutoProcessor
    print("Loading checkpoint shards â€¦")
    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        MODEL_PATH, torch_dtype="auto", device_map="auto"
    )
    processor = AutoProcessor.from_pretrained(MODEL_PATH)
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")
    return model, processor

# ====== å•æ¬¡æ¨ç†å¹¶è®¡æ—¶ ======
def infer_clip(model, processor, clip_path):
    from qwen_vl_utils import process_vision_info

    # æ„é€  messagesï¼ˆåªåœ¨è¿™é‡Œè®¾ç½® fps / max_pixelsï¼Œé¿å…é‡å¤ï¼‰
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "video",
                    "video": "file://" + clip_path,
                    "fps": float(INFER_FPS),
                    "max_pixels": int(INFER_MAX_PIXELS),
                },
                {"type": "text", "text": "è¯·ç®€è¦æè¿°è¿™ä¸ªç‰‡æ®µã€‚"},
            ],
        }
    ]

    # å‡†å¤‡è¾“å…¥
    t0 = time.perf_counter()
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    image_inputs, video_inputs, video_kwargs = process_vision_info(messages, return_video_kwargs=True)

    # pack
    t_pack0 = time.perf_counter()
    inputs = processor(
        text=[text],
        images=image_inputs,
        videos=video_inputs,
        padding=True,
        return_tensors="pt",
        **video_kwargs,      # è¿™é‡Œåªä¼ ä¸€æ¬¡fpsç­‰
    ).to(model.device)
    t_pack1 = time.perf_counter()

    # ç”Ÿæˆ
    t_gen0 = time.perf_counter()
    output_ids = model.generate(**inputs, max_new_tokens=MAX_NEW_TOKENS, do_sample=False)
    t_gen1 = time.perf_counter()

    # è§£ç 
    t_dec0 = time.perf_counter()
    trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, output_ids)]
    text_out = processor.batch_decode(trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]
    t_dec1 = time.perf_counter()

    return {
        "pack_sec": round(t_pack1 - t_pack0, 4),
        "gen_sec": round(t_gen1 - t_gen0, 4),
        "decode_sec": round(t_dec1 - t_dec0, 4),
        "total_sec": round(t_dec1 - t0, 4),
        "preview": text_out[:120].replace("\n", " "),
    }, None

# ====== ä¸»æµç¨‹ ======
def main():
    rows = []
    os.makedirs(OUT_DIR, exist_ok=True)

    # å…ˆåŠ è½½æ¨¡å‹
    model, processor = load_model_and_processor()

    for r in RATIOS:
        print(f"\nâ–¶ï¸ æ¯”ä¾‹ {r}% â€”â€” ç”Ÿæˆä¸­å¿ƒç‰‡æ®µå¹¶æ¨ç†")
        try:
            clip_info, note = write_center_clip(VIDEO_PATH, r, SAMPLED_DIR)
            if not clip_info:
                rows.append({
                    "ratio": r, "start_sec": None, "dur_sec": None, "fps": None, "frames": None,
                    "pack_sec": None, "gen_sec": None, "decode_sec": None, "total_sec": None,
                    "ok": False, "note": note or "write failed", "preview": ""
                })
                print("âŒ ç‰‡æ®µå¯¼å‡ºå¤±è´¥ï¼š", note)
                continue

            print(f"ä¸­å¿ƒç‰‡æ®µï¼šstart={clip_info['start_sec']:.2f}s, dur={clip_info['dur_sec']:.2f}s, "
                  f"fps={clip_info['fps']:.3f}, frames={clip_info['frames']}, file={clip_info['path']}")

            # æ¨ç†è®¡æ—¶
            stats, err = infer_clip(model, processor, clip_info["path"])
            if err:
                rows.append({
                    "ratio": r, "start_sec": clip_info["start_sec"], "dur_sec": clip_info["dur_sec"],
                    "fps": clip_info["fps"], "frames": clip_info["frames"],
                    "pack_sec": None, "gen_sec": None, "decode_sec": None, "total_sec": None,
                    "ok": False, "note": err, "preview": ""
                })
                print("âŒ æ¨ç†å¤±è´¥ï¼š", err)
                continue

            rows.append({
                "ratio": r,
                "start_sec": round(clip_info["start_sec"], 6),
                "dur_sec": round(clip_info["dur_sec"], 6),
                "fps": round(clip_info["fps"], 3),
                "frames": clip_info["frames"],
                **stats,
                "ok": True,
                "note": "ok",
            })
            print(f"â± pack={stats['pack_sec']}s  gen={stats['gen_sec']}s  decode={stats['decode_sec']}s  total={stats['total_sec']}s")
            print(f"ğŸ“ é¢„è§ˆï¼š{rows[-1]['preview']}")

        except torch.cuda.OutOfMemoryError as oom:
            torch.cuda.empty_cache()
            rows.append({
                "ratio": r, "start_sec": None, "dur_sec": None, "fps": None, "frames": None,
                "pack_sec": None, "gen_sec": None, "decode_sec": None, "total_sec": None,
                "ok": False, "note": f"CUDA OOM: {oom}", "preview": ""
            })
            print("âŒ OOMï¼š", str(oom))
        except Exception as e:
            rows.append({
                "ratio": r, "start_sec": None, "dur_sec": None, "fps": None, "frames": None,
                "pack_sec": None, "gen_sec": None, "decode_sec": None, "total_sec": None,
                "ok": False, "note": f"Error: {e}", "preview": ""
            })
            print("âŒ å¼‚å¸¸ï¼š", str(e))
            print(traceback.format_exc())

    # ä¿å­˜ Excel
    df = pd.DataFrame(rows, columns=[
        "ratio", "start_sec", "dur_sec", "fps", "frames",
        "pack_sec", "gen_sec", "decode_sec", "total_sec",
        "ok", "note", "preview"
    ])
    df.to_excel(EXCEL_PATH, index=False)
    print("\nâœ… å·²ä¿å­˜ Excelï¼š", EXCEL_PATH)
    print("ğŸ“ é‡‡æ ·è§†é¢‘ç›®å½•ï¼š", SAMPLED_DIR)

if __name__ == "__main__":
    main()
